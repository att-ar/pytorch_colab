{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "FeEItPoKr4an",
      "metadata": {
        "id": "FeEItPoKr4an"
      },
      "source": [
        "# Testing Branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9tSoZ1FlqfT",
      "metadata": {
        "id": "c9tSoZ1FlqfT"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kO6jZ26ahKAo",
      "metadata": {
        "id": "kO6jZ26ahKAo"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/pytorch_colab/rolling_and_plot.py .\n",
        "!cp /content/drive/MyDrive/pytorch_colab/sim_data.csv ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95327a6b",
      "metadata": {
        "id": "95327a6b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader #, Dataset\n",
        "# from torch.nn.modules.activation import Sigmoid\n",
        "\n",
        "# from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "from dataclasses import dataclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f82e61bc",
      "metadata": {
        "id": "f82e61bc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip install jupyterplot\n",
        "from jupyterplot import ProgressPlot as PP\n",
        "\n",
        "from rolling_and_plot import data_plot, normalize, rolling_split, validate\n",
        "from lstm_classes import *\n",
        "\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8682404",
      "metadata": {
        "id": "b8682404"
      },
      "outputs": [],
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = torch.device(\"cpu\")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "855a2f5a",
      "metadata": {
        "id": "855a2f5a"
      },
      "source": [
        "# TOC\n",
        "\n",
        "* [Preprocessing](#pre)\n",
        "\n",
        "* [Data Loading](#dload)\n",
        "\n",
        "* [Models](#model)\n",
        "\n",
        "* [Training](#train)\n",
        "\n",
        "* [Validate](#val)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8546a708",
      "metadata": {
        "id": "8546a708"
      },
      "source": [
        "<a id=\"pre\"></a>\n",
        "# PreProcessing "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3NXDQtonXeB2",
      "metadata": {
        "id": "3NXDQtonXeB2"
      },
      "source": [
        "## <a id=\"g\">G class</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2665c76",
      "metadata": {
        "id": "a2665c76"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class G:\n",
        "    capacity = 20 #Ampere hours\n",
        "    num_features = 3 # current, voltage, soc\n",
        "    lstm_nodes = 256\n",
        "    window_time = 64 #seconds\n",
        "    window_size = 16\n",
        "    slicing = window_time // window_size\n",
        "    batch_size = 16\n",
        "    epochs = 128 # should use a power of `T_mult` if you're using cosine annealing, because the cycles restart on a power of `T_mult`\n",
        "    learning_rate = 0.0035\n",
        "    weight_decay = 0 # Do not implement weight decay alongside batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b40018fb",
      "metadata": {
        "id": "b40018fb"
      },
      "outputs": [],
      "source": [
        "file = pd.read_csv(\"/content/sim_data.csv\")\n",
        "file[\"soc\"] *= 100 #if sim_data.csv only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "346737b3",
      "metadata": {
        "id": "346737b3"
      },
      "outputs": [],
      "source": [
        "data_plot(data = [file],\n",
        "          title=\"OCV v SOC\",\n",
        "          x = [\"test time (sec)\"],\n",
        "          y = [\"soc\"],\n",
        "          markers = \"lines\",\n",
        "          color = \"darkorchid\",\n",
        "          x_title = \"Test Time (sec)\",\n",
        "          y_title = \"SOC\"\n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13977196",
      "metadata": {
        "id": "13977196"
      },
      "outputs": [],
      "source": [
        "file = normalize(file.loc[:,[\"current\",\"voltage\",\"soc\"]].iloc[::G.slicing], G.capacity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5652432",
      "metadata": {
        "id": "c5652432"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = rolling_split(file, G.window_size)\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3de98f4e",
      "metadata": {
        "id": "3de98f4e"
      },
      "source": [
        "# Data Loader <a id=\"dload\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eea0306a",
      "metadata": {
        "id": "eea0306a"
      },
      "outputs": [],
      "source": [
        "train_dataloader = BatterySet(x_train, y_train)\n",
        "test_dataloader = BatterySet(x_test, y_test)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataloader, batch_size=G.batch_size, shuffle=False, drop_last = True)\n",
        "test_dataloader = DataLoader(test_dataloader, batch_size=G.batch_size, shuffle=False, drop_last = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d737277d",
      "metadata": {
        "id": "d737277d"
      },
      "outputs": [],
      "source": [
        "for X,y in train_dataloader:\n",
        "    print(f\"Shape of X [window, features]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ef3bc72",
      "metadata": {
        "id": "3ef3bc72",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# for batch, (x,y) in enumerate(test_dataloader.dataset):\n",
        "#     print(batch,x,y)\n",
        "#     break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2625e83a",
      "metadata": {
        "id": "2625e83a"
      },
      "source": [
        "# Creating Models <a id=\"model\"></a>\n",
        "\n",
        "Go to [G class](#g)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "r-73IGFpGJ4o",
      "metadata": {
        "id": "r-73IGFpGJ4o"
      },
      "source": [
        "Can load a pretrained model, the cell is after the optimizer cell.<br>You need to run the cell right below this first though."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZbJiryd_KYPJ",
      "metadata": {
        "id": "ZbJiryd_KYPJ"
      },
      "outputs": [],
      "source": [
        "model = LSTMNetwork().to(device)\n",
        "compiled_model = torch.compile(model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d654020d",
      "metadata": {},
      "source": [
        "`torch.compile` introduced in the nightly release (makes the model much more efficient). Can use additional arguments to either reduce overhead (and increase memory usage) or make the model as efficient as possible (takes a lot longer to compile)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ccde997",
      "metadata": {
        "id": "0ccde997"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer, epoch):\n",
        "    size = len(dataloader)\n",
        "    train_loss, perc_error = 0.0, 0.0\n",
        "    model.train()\n",
        "    for batch, (x,y) in enumerate(dataloader):\n",
        "        optimizer.zero_grad() #resets the gradient graph\n",
        "        \n",
        "        #forward\n",
        "        predict = model(x)\n",
        "        loss = loss_fn(predict, y).mean(0) # assert(loss.shape == (1))\n",
        "\n",
        "        #backward\n",
        "        loss.backward()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.step()\n",
        "        ##### For OneCycleLR:\n",
        "        scheduler.step()\n",
        "        ##### For CosineAnnealingWarmRestarts:\n",
        "        # scheduler.step(epoch + (batch+1) // size)\n",
        "\n",
        "        if loss.isnan():\n",
        "            print(\"loss was NaN\")\n",
        "            break\n",
        "\n",
        "        if batch % (size // 3) == 0:\n",
        "            print(f\"batch mean loss: {loss.item():>7f}  [{batch:4d}/{size:4d}]\")\n",
        "\n",
        "        with torch.no_grad(): #used to check bias and variance by comparing with test set\n",
        "            perc_error += torch.mean(torch.abs(predict - y) / (y+ 1e-2) * 100, (0,1))\n",
        "        \n",
        "    train_loss /= size\n",
        "    perc_error /= size\n",
        "    print(f\"Train Error: \\nAverage Accuracy: {100 - perc_error}%, Avg Loss: {train_loss:>8f}\\n\")\n",
        "    return train_loss, 100.0 - perc_error\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader)\n",
        "    test_loss, perc_error = 0.0, 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad(): #doesnt update parameters (we are testing not training)\n",
        "        for counter, (x,y) in enumerate(dataloader):\n",
        "            predict = model(x).reshape(y.shape)\n",
        "            test_loss += loss_fn(predict, y).mean(0).item()\n",
        "            perc_error += torch.mean(torch.abs(predict - y) / (y+ 1e-2) * 100, (0,1))\n",
        "           \n",
        "            counter += 1\n",
        "            if counter % (size // 2) == 0:\n",
        "                print(f\"{counter} / {size} tested\")\n",
        "\n",
        "    test_loss /= size\n",
        "    perc_error /= size\n",
        "    print(f\"Test Error: \\nAverage Accuracy: {100 - perc_error}%, Avg Loss: {test_loss:>8f}\\n\")\n",
        "    return test_loss, 100.0 - perc_error"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "I0LawDbNo2ht",
      "metadata": {
        "id": "I0LawDbNo2ht"
      },
      "source": [
        "**Literature**\n",
        "\n",
        "*Loss*<br>\n",
        "The LogCoshLoss is the Loss function used by Hannan et al. in their article in the Journal *Nature*: [Deep learning approach towards accurate state of charge estimation for lithium-ion batteries using self-supervised transformer model](https://www.nature.com/articles/s41598-021-98915-8).\n",
        "\n",
        "However they used a Transformer Network\n",
        "\n",
        "*Learning Rate*<br>\n",
        "The OneCycle learning rate scheduler with cosine annealing introduced by Leslie N. Smith in his paper [A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay](https://doi.org/10.48550/arXiv.1803.09820), seems to be the best scheduler according to Fast.AI\n",
        "\n",
        " - The original 3-phase approach seems to work significantly better than the 2-phase method by Fast.AI\n",
        "\n",
        "Cosine annealing with warm restarts proposed by Loshchilov et al. in [SGDR: Stochastic Gradient Descent with Warm Restarts](https://doi.org/10.48550/arXiv.1608.03983)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c58545e",
      "metadata": {
        "id": "0c58545e"
      },
      "outputs": [],
      "source": [
        "# loss_fn = nn.HuberLoss()\n",
        "loss_fn = LogCoshLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(compiled_model.parameters(),\n",
        "                             lr = G.learning_rate,\n",
        "                             weight_decay= G.weight_decay\n",
        "                            )\n",
        "\n",
        "#OneCycle scheduler needs step() to be called after every batch\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
        "                                                G.learning_rate, #max_lr\n",
        "                                                epochs = G.epochs,\n",
        "                                                steps_per_epoch = len(train_dataloader),\n",
        "                                                anneal_strategy = \"cos\", #cosine annealing\n",
        "                                                div_factor = 35,\n",
        "                                                three_phase = True,\n",
        "                                                verbose = False\n",
        "                                                )\n",
        "\n",
        "#CosineAnnealing with WarmRestarts, step() can be called after every batch but it is dependent of epoch:\n",
        "# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer,\n",
        "#                                                                  T_0 = 1,\n",
        "#                                                                  T_mult = 4,\n",
        "#                                                                  eta_min = 7e-11,\n",
        "#                                                                  verbose = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ryPjaJi9IQcX",
      "metadata": {
        "id": "ryPjaJi9IQcX"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(\n",
        "    torch.load(\"drive/MyDrive/pytorch_colab/sim_model_state_dict.pth\",\n",
        "    map_location = device)\n",
        "    )\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MR-ZR2DSq8_B",
      "metadata": {
        "id": "MR-ZR2DSq8_B"
      },
      "source": [
        "# Training <a id=\"train\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1886bf",
      "metadata": {
        "id": "de1886bf"
      },
      "outputs": [],
      "source": [
        "pp = PP(plot_names = [\"Mean Log Loss\", \"% Accuracy\"],\n",
        "        line_names = [\"Train Loop\", \"Test Loop\"],\n",
        "        x_label = \"epochs\"\n",
        "       )\n",
        "\n",
        "for epoch in range(1, G.epochs + 1):\n",
        "    print(f\"Epoch {epoch}/{G.epochs}\\n----------------------------------------\")\n",
        "    train_loss, train_acc = train_loop(train_dataloader, compiled_model, loss_fn, optimizer, epoch)\n",
        "    test_loss, test_acc = test_loop(test_dataloader, compiled_model, loss_fn)\n",
        "    \n",
        "    pp.update([[train_loss, test_loss], [train_acc, test_acc]])\n",
        "\n",
        "    # if (epoch != 0) and (epoch % 50 == 0):\n",
        "    #     torch.save(model.state_dict(), \"drive/MyDrive/pytorch_colab/model.pth\")\n",
        "    #     print(\"Saved the model parameters\\n\")\n",
        "\n",
        "print(\"Completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hZsMkW3QyOJU",
      "metadata": {
        "id": "hZsMkW3QyOJU"
      },
      "outputs": [],
      "source": [
        "torch.save(compiled_model.state_dict(), \"drive/MyDrive/pytorch_colab/sim_model_state_dict.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AQWJiqiCo1XA",
      "metadata": {
        "id": "AQWJiqiCo1XA"
      },
      "source": [
        "# Validation <a id=\"val\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "elvx2vg1pGY7",
      "metadata": {
        "id": "elvx2vg1pGY7"
      },
      "source": [
        "**Dev Set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ILWoMlHdvRlX",
      "metadata": {
        "id": "ILWoMlHdvRlX"
      },
      "outputs": [],
      "source": [
        "visualize_dev = validate(compiled_model, test_dataloader, dev = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KQpORafIpKPL",
      "metadata": {
        "id": "KQpORafIpKPL"
      },
      "source": [
        "**Entire Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gKy0e9uXpMX9",
      "metadata": {
        "id": "gKy0e9uXpMX9"
      },
      "outputs": [],
      "source": [
        "x_set, y_set = rolling_split(file, G.window_size, train = False)\n",
        "\n",
        "set_dataloader = BatterySet(x_set, y_set)\n",
        "set_dataloader = DataLoader(set_dataloader, batch_size=G.batch_size, shuffle=False, drop_last = True)\n",
        "\n",
        "visualize = validate(compiled_model, set_dataloader, dev = False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LSTM-Model.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:07:06) [Clang 13.0.1 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "c6bfa5ab41bc5884aca772abc33d700e8cb163d4848f18a19fbc284a227fb0ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
